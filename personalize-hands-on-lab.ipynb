{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon Personalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to Use the Notebook\n",
    "\n",
    "Code is broken up into cells like the one below. There's a triangular `Run` button at the top of this page you can click to execute each cell and move onto the next, or you can press `Shift` + `Enter` while in the cell to execute it and move onto the next one.\n",
    "\n",
    "As a cell is executing you'll notice a line to the side showcase an `*` while the cell is running or it will update to a number to indicate the last cell that completed executing after it has finished exectuting all the code within a cell.\n",
    "\n",
    "\n",
    "Simply follow the instructions below and execute the cells to get started with Amazon Personalize."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Imports \n",
    "\n",
    "Python ships with a broad collection of libraries and we need to import those as well as the ones installed to help us like [boto3](https://aws.amazon.com/sdk-for-python/) (AWS SDK for python) and [Pandas](https://pandas.pydata.org/)/[Numpy](https://numpy.org/) which are core data science tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import boto3\n",
    "import sagemaker\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "# !conda install -y -c conda-forge unzip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next you will want to validate that your environment can communicate successfully with Amazon Personalize, the lines below do just that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Define Boto3, Policy and Role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = '20221023'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the SDK to Personalize:\n",
    "personalize = boto3.client('personalize')\n",
    "personalize_runtime = boto3.client('personalize-runtime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = sagemaker.Session().default_bucket()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-1. Attach Policy to S3 Bucket\n",
    "\n",
    "Amazon Personalize needs to be able to read the content of your S3 bucket that you created earlier. The lines below will do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client(\"s3\")\n",
    "\n",
    "policy = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Id\": \"PersonalizeS3BucketAccessPolicy\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Sid\": \"PersonalizeS3BucketAccessPolicy\",\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Principal\": {\n",
    "                \"Service\": \"personalize.amazonaws.com\"\n",
    "            },\n",
    "            \"Action\": [\n",
    "                \"s3:GetObject\",\n",
    "                \"s3:ListBucket\"\n",
    "            ],\n",
    "            \"Resource\": [\n",
    "                \"arn:aws:s3:::{}\".format(bucket),\n",
    "                \"arn:aws:s3:::{}/*\".format(bucket)\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "s3.put_bucket_policy(Bucket=bucket, Policy=json.dumps(policy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-2. Create Personalize Role\n",
    "\n",
    "Also Amazon Personalize needs the ability to assume Roles in AWS in order to have the permissions to execute certain tasks, the lines below grant that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iam = boto3.client(\"iam\")\n",
    "\n",
    "role_name = f\"PersonalizeRoleDemo-{date}\"\n",
    "assume_role_policy_document = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "          \"Effect\": \"Allow\",\n",
    "          \"Principal\": {\n",
    "            \"Service\": \"personalize.amazonaws.com\"\n",
    "          },\n",
    "          \"Action\": \"sts:AssumeRole\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "create_role_response = iam.create_role(\n",
    "    RoleName = role_name,\n",
    "    AssumeRolePolicyDocument = json.dumps(assume_role_policy_document)\n",
    ")\n",
    "\n",
    "# AmazonPersonalizeFullAccess provides access to any S3 bucket with a name that includes \"personalize\" or \"Personalize\" \n",
    "# if you would like to use a bucket with a different name, please consider creating and attaching a new policy\n",
    "# that provides read access to your bucket or attaching the AmazonS3ReadOnlyAccess policy to the role\n",
    "policy_arn = \"arn:aws:iam::aws:policy/service-role/AmazonPersonalizeFullAccess\"\n",
    "iam.attach_role_policy(\n",
    "    RoleName = role_name,\n",
    "    PolicyArn = policy_arn\n",
    ")\n",
    "\n",
    "# Now add S3 support\n",
    "iam.attach_role_policy(\n",
    "    PolicyArn='arn:aws:iam::aws:policy/AmazonS3FullAccess',\n",
    "    RoleName=role_name\n",
    ")\n",
    "time.sleep(10) # wait for a minute to allow IAM role policy attachment to propagate\n",
    "\n",
    "role_arn = create_role_response[\"Role\"][\"Arn\"]\n",
    "print(role_arn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create Sample Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-1. Interactions Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "\n",
    "TIMESTAMP = time.mktime((datetime.now()-timedelta(days=100)).timetuple())\n",
    "TIMESTAMP = int(TIMESTAMP)\n",
    "TIMESTAMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = [i+1 for i in range(100)]\n",
    "item_id = [i+1000 for i in range(10000)]\n",
    "item_type = ['AAA','BBB','CCC']\n",
    "event_val = [i+1 for i in range(10)]\n",
    "event_type = ['purchased','checked']\n",
    "print(f\"USER_ID : {user_id[:10]} \\nITEM_ID : {item_id[:10]} \\nITEM_TYPE : {item_type} \\nEVENT_VALUE : {event_val} \\nEVENT_TYPE : {event_type}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_mapping={}\n",
    "for item in item_id:\n",
    "    item_mapping[item] = random.choice(item_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interaction_data = []\n",
    "for i in range(1000):\n",
    "    event_type_tmp = random.choice(event_type)\n",
    "    if event_type_tmp == 'checked':\n",
    "        event_val_tmp = random.choice(event_val)\n",
    "    else:\n",
    "        event_val_tmp = None\n",
    "    select_item_id = random.choice(item_id)\n",
    "    select_item_type = item_mapping[select_item_id]\n",
    "    interaction_data.append([random.choice(user_id),select_item_id, \n",
    "                 TIMESTAMP+random.choice(range(10000,4320108)), select_item_type,\n",
    "                 event_val_tmp, event_type_tmp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interaction_pd_data=pd.DataFrame(interaction_data, columns=['USER_ID', 'ITEM_ID', 'TIMESTAMP', 'ITEM_TYPE', 'EVENT_VALUE', 'EVENT_TYPE'])\n",
    "interaction_pd_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_interaction_filename = f\"interaction_sample_{date}.csv\"\n",
    "interaction_pd_data.to_csv(sample_interaction_filename, index=False)\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(sample_interaction_filename).upload_file(sample_interaction_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2. Users dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_meta_1 = []\n",
    "\n",
    "for i in range(10):\n",
    "    user_meta_1.append(f'USER_GROUP_{i}')\n",
    "\n",
    "user_meta_2 = [i for i in range(100,105)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_data = []\n",
    "for i in user_id:\n",
    "    user_data.append([i,random.choice(user_meta_1),random.choice(user_meta_2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_pd_data=pd.DataFrame(user_data, columns=['USER_ID', 'USER_META1', 'USER_META2'])\n",
    "user_pd_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_user_filename = f\"users_sample_{date}.csv\"\n",
    "user_pd_data.to_csv(sample_user_filename, index=False)\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(sample_user_filename).upload_file(sample_user_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-3. Items dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"food is any substance consumed to provide nutritional support for an organism. Food is usually of plant, animal, or fungal origin, and contains essential nutrients, such as carbohydrates, fats, proteins, vitamins, or minerals. The substance is ingested by an organism and assimilated by the organism's cells to provide energy, maintain life, or stimulate growth. Different species of animals have different feeding behaviours that satisfy the needs of their unique metabolisms, often evolved to fill a specific ecological niche within specific geographical contexts. Omnivorous humans are highly adaptable and have adapted to obtain food in many different ecosystems. Historically, humans secured food through two main methods: hunting and gathering and agriculture. As agricultural technologies increased, humans settled into agriculture lifestyles with diets shaped by the agriculture opportunities in their geography. Geographic and cultural differences has led to creation of numerous cuisines and culinary arts, including a wide array of ingredients, herbs, spices, techniques, and dishes. As cultures have mixed through forces like international trade and globalization, ingredients have become more widely available beyond their geographic and cultural origins, creating a cosmopolitan exchange of different food traditions and practices. Today, the majority of the food energy required by the ever-increasing population of the world is supplied by the industrial food industry, which produces food with intensive agriculture and distributes it through complex food processing and food distribution systems. This system of conventional agriculture relies heavily on fossil fuels, which means that the food and agricultural system is one of the major contributors to climate change, accountable for as much as 37% of total greenhouse gas emissions. Addressing the carbon intensity of the food system and food waste are important mitigation measures in the global response to climate change. The food system has significant impacts on a wide range of other social and political issues including: sustainability, biological diversity, economics, population growth, water supply, and access to food. The right to food is a human right derived from the International Covenant on Economic, Social and Cultural Rights, recognizing the right to an adequate standard of living, including adequate food, as well as the fundamental right to be free from hunger. Because of these fundamental rights, food security is often a priority international policy activity; for example Sustainable Development Goal 2 Zero hunger is meant to eliminate hunger by 2030. Food safety and food security are monitored by international agencies like the International Association for Food Protection, World Resources Institute, World Food Programme, Food and Agriculture Organization, and International Food Information Council, and are often subject to national regulation by institutions, like the Food and Drug Administration in the United States. Food is any substance consumed to provide nutritional support and energy to an organism. It can be raw, processed or formulated and is consumed orally by animals for growth, health or pleasure. Food is mainly composed of water, lipids, proteins and carbohydrates. Minerals and organic substances vitamins can also be found in food. Plants, algae and some microorganisms use photosynthesis to make their own food molecules. Water is found in many foods and has been defined as a food by itself. Water and fiber have low energy densities, or calories, while fat is the most energy dense component. Some inorganic (non-food) elements are also essential for plant and animal functioning. Human food can be classified in various ways, either by related content or by how the food is processed. The number and composition of food groups can vary. Most systems include four basic groups that describe their origin and relative nutritional function: Vegetables and Fruit, Cereals and Bread, Dairy, and Meat. Studies that look into diet quality often group food into whole grains, cereals, refined grains/cereals, vegetables, fruits, nuts, legumes, eggs, dairy products, fish, red meat, processed meat, and sugar-sweetened beverages. The Food and Agriculture Organization and World Health Organization use a system with nineteen food classifications: cereals, roots, pulses and nuts, milk, eggs, fish and shellfish, meat, insects, vegetables, fruits, fats and oils, sweets and sugars, spices and condiments, beverages, foods for nutritional uses, food additives, composite dishes and savoury snacks.Plants as a food source are often divided into seeds, fruits, vegetables, legumes, grains and nuts. Where plants fall within these categories can vary with botanically described fruits such as the tomato, squash, pepper and eggplant or seeds like peas commonly considered vegetables. Food is a fruit if the part eaten is derived from the reproductive tissue, so seeds, nuts and grains are technically fruit. From a culinary perspective fruits are generally considered the remains of botanically described fruits after grains, nuts, seeds and fruits used as vegetables are removed. Grains can be defined as seeds that humans eat or harvest, with cereal grains oats, wheat, rice, corn, barley, rye, sorghum and millet belonging to the Poaceae grass family and pulses coming from the Fabaceae legume family. Whole grains are foods that contain all the elements of the original seed bran, germ, and endosperm. Nuts are dry fruits distinguishable by their woody shell.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_meta_1 = []\n",
    "\n",
    "for i in range(5):\n",
    "    item_meta_1.append(f'ITEM_GROUP_{i+1}')\n",
    "\n",
    "item_meta_2 = []\n",
    "\n",
    "for i in range(5):\n",
    "    item_meta_2.append(f'ITEM_GROUP_10000{i+1}')\n",
    "\n",
    "candidate_desc = text.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_data = []\n",
    "for i in item_id:\n",
    "    description = []\n",
    "    desc_text = ''\n",
    "    for word in random.sample(candidate_desc, random.choice(range(15,50))):\n",
    "        desc_text += word + ' '\n",
    "#     description.append(desc_text)\n",
    "    select_item_meta_1 = random.choice(item_meta_1)\n",
    "    select_item_meta_2 = random.choice(item_meta_2)\n",
    "    \n",
    "    item_data.append([i,select_item_meta_1,select_item_meta_2,\n",
    "                      TIMESTAMP+random.choice(range(10000,4320108)), \n",
    "                      desc_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_pd_data=pd.DataFrame(item_data, columns=['ITEM_ID','ITEM_META1','ITEM_META2','CREATION_TIMESTAMP','DESCRIPTION'])\n",
    "item_pd_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_item_filename = f\"items_sample_{date}.csv\"\n",
    "item_pd_data.to_csv(sample_item_filename, index=False)\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(sample_item_filename).upload_file(sample_item_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create Schema\n",
    "\n",
    "A core component of how Personalize understands your data comes from the Schema that is defined below. This configuration tells the service how to digest the data provided via your CSV file. Note the columns and types align to what was in the file you created above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-1. Interactions datasets schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_schema_name = f'interactions-samples-{date}'\n",
    "try:\n",
    "    personalize.delete_schema(schemaArn=f'arn:aws:personalize:us-west-2:687314952804:schema/{interactions_schema_name}')\n",
    "except:\n",
    "    print(\"The schema doesn't exist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_schema = {\n",
    "    \"type\": \"record\",\n",
    "    \"name\": \"Interactions\",\n",
    "    \"namespace\": \"com.amazonaws.personalize.schema\",\n",
    "    \"fields\": [\n",
    "        {\n",
    "            \"name\": \"USER_ID\",\n",
    "            \"type\": \"string\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"ITEM_ID\",\n",
    "            \"type\": \"string\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"TIMESTAMP\",\n",
    "            \"type\": \"long\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"ITEM_TYPE\",\n",
    "            \"type\": \"string\",\n",
    "            \"categorical\": True\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"EVENT_VALUE\",\n",
    "            \"type\": [\n",
    "             \"float\",\n",
    "             \"null\"\n",
    "          ]\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"EVENT_TYPE\",\n",
    "            \"type\": \"string\"\n",
    "        }\n",
    "    ],\n",
    "    \"version\": \"1.0\"\n",
    "}\n",
    "\n",
    "interactions_create_schema_response = personalize.create_schema(\n",
    "    name = interactions_schema_name,\n",
    "    schema = json.dumps(interactions_schema)\n",
    ")\n",
    "\n",
    "interactions_schema_arn = interactions_create_schema_response['schemaArn']\n",
    "print(json.dumps(interactions_create_schema_response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-2. User datasets schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_schema_name = f'user-samples-{date}'\n",
    "try:\n",
    "    personalize.delete_schema(schemaArn=f'arn:aws:personalize:us-west-2:687314952804:schema/{users_schema_name}')\n",
    "except:\n",
    "    print(\"The schema doesn't exist\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_schema = {\n",
    "    \"type\": \"record\",\n",
    "    \"name\": \"Users\",\n",
    "    \"namespace\": \"com.amazonaws.personalize.schema\",\n",
    "    \"fields\": [\n",
    "        {\n",
    "            \"name\": \"USER_ID\",\n",
    "            \"type\": \"string\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"USER_META1\",\n",
    "            \"type\": \"string\",\n",
    "            \"categorical\": True\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"USER_META2\",\n",
    "            \"type\": \"int\"\n",
    "        }\n",
    "    ],\n",
    "    \"version\": \"1.0\"\n",
    "}\n",
    "\n",
    "users_create_schema_response = personalize.create_schema(\n",
    "    name = users_schema_name,\n",
    "    schema = json.dumps(users_schema)\n",
    ")\n",
    "\n",
    "users_schema_arn = users_create_schema_response['schemaArn']\n",
    "print(json.dumps(users_create_schema_response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-3. Items datasets schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_schema_name = f'items-samples-{date}'\n",
    "try:\n",
    "    personalize.delete_schema(schemaArn=f'arn:aws:personalize:us-west-2:687314952804:schema/{items_schema_name}')\n",
    "except:\n",
    "    print(\"The schema doesn't exist\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_schema = {\n",
    "    \"type\": \"record\",\n",
    "    \"name\": \"Items\",\n",
    "    \"namespace\": \"com.amazonaws.personalize.schema\",\n",
    "    \"fields\": [\n",
    "        {\n",
    "            \"name\": \"ITEM_ID\",\n",
    "            \"type\": \"string\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"ITEM_META1\",\n",
    "            \"type\": [\n",
    "                \"null\",\n",
    "                \"string\"\n",
    "              ],\n",
    "              \"categorical\": True\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"ITEM_META2\",\n",
    "            \"type\": [\n",
    "                \"null\",\n",
    "                \"string\"\n",
    "              ],\n",
    "              \"categorical\": True\n",
    "        },\n",
    "        {\n",
    "          \"name\": \"CREATION_TIMESTAMP\",\n",
    "          \"type\": \"long\"\n",
    "        },\n",
    "        {\n",
    "          \"name\": \"DESCRIPTION\",\n",
    "          \"type\": [\n",
    "            \"null\",\n",
    "            \"string\"\n",
    "          ],\n",
    "          \"textual\": True\n",
    "        },\n",
    "    ],\n",
    "    \"version\": \"1.0\"\n",
    "}\n",
    "\n",
    "items_create_schema_response = personalize.create_schema(\n",
    "    name = items_schema_name,\n",
    "    schema = json.dumps(items_schema)\n",
    ")\n",
    "\n",
    "items_schema_arn = items_create_schema_response['schemaArn']\n",
    "print(json.dumps(items_create_schema_response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create Dataset Group\n",
    "\n",
    "The largest grouping in Personalize is a Dataset Group, this will isolate your data, event trackers, solutions, and campaigns. Grouping things together that share a common collection of data. Feel free to alter the name below if you'd like."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-1. Dataset group details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_dataset_group_response = personalize.create_dataset_group(\n",
    "    name = f\"dataset-samples-{date}\"\n",
    ")\n",
    "\n",
    "dataset_group_arn = create_dataset_group_response['datasetGroupArn']\n",
    "print(json.dumps(create_dataset_group_response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Wait for Dataset Group to Have ACTIVE Status\n",
    "\n",
    "Before we can use the Dataset Group in any items below it must be active, execute the cell below and wait for it to show active."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_time = time.time() + 3*60*60 # 3 hours\n",
    "while time.time() < max_time:\n",
    "    describe_dataset_group_response = personalize.describe_dataset_group(\n",
    "        datasetGroupArn = dataset_group_arn\n",
    "    )\n",
    "    status = describe_dataset_group_response[\"datasetGroup\"][\"status\"]\n",
    "    print(\"DatasetGroup: {}\".format(status))\n",
    "    \n",
    "    if status == \"ACTIVE\" or status == \"CREATE FAILED\":\n",
    "        break\n",
    "        \n",
    "    time.sleep(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-2. Create Datasets\n",
    "\n",
    "After the group, the next thing to create is the actual datasets. Execute the cells below to create it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4-2-1. Interactions Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_dataset_type = \"INTERACTIONS\"\n",
    "try:\n",
    "    interactions_create_dataset_response = personalize.create_dataset(\n",
    "        name = f\"interactions-samples-dataset-{date}\",\n",
    "        datasetType = interactions_dataset_type,\n",
    "        datasetGroupArn = dataset_group_arn,\n",
    "        schemaArn = interactions_schema_arn\n",
    "    )\n",
    "\n",
    "    interactions_dataset_arn = interactions_create_dataset_response['datasetArn']\n",
    "    print(json.dumps(interactions_create_dataset_response, indent=2))\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4-2-2. Users Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_dataset_type = \"USERS\"\n",
    "try:\n",
    "    users_create_dataset_response = personalize.create_dataset(\n",
    "        name = f\"users-samples-dataset-{date}\",\n",
    "        datasetType = users_dataset_type,\n",
    "        datasetGroupArn = dataset_group_arn,\n",
    "        schemaArn = users_schema_arn\n",
    "    )\n",
    "\n",
    "    users_dataset_arn = users_create_dataset_response['datasetArn']\n",
    "    print(json.dumps(users_create_dataset_response, indent=2))\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4-2-3. Items Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_dataset_type = \"ITEMS\"\n",
    "try:\n",
    "    items_create_dataset_response = personalize.create_dataset(\n",
    "        name = f\"items-samples-dataset-{date}\",\n",
    "        datasetType = items_dataset_type,\n",
    "        datasetGroupArn = dataset_group_arn,\n",
    "        schemaArn = items_schema_arn\n",
    "    )\n",
    "\n",
    "    items_dataset_arn = items_create_dataset_response['datasetArn']\n",
    "    print(json.dumps(items_create_dataset_response, indent=2))\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-3. Dataset Import jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-3-1. Create dataset import job for Interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(10)\n",
    "try:\n",
    "    interactions_create_dataset_import_job_response = personalize.create_dataset_import_job(\n",
    "        jobName = f\"import-sample-interactions-{date}\",\n",
    "        datasetArn = interactions_dataset_arn,\n",
    "        dataSource = {\n",
    "            \"dataLocation\": \"s3://{}/{}\".format(bucket, sample_interaction_filename)\n",
    "        },\n",
    "        roleArn = role_arn\n",
    "    )\n",
    "\n",
    "    interactions_dataset_import_job_arn = interactions_create_dataset_import_job_response['datasetImportJobArn']\n",
    "    print(json.dumps(interactions_create_dataset_import_job_response, indent=2))\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-3-2. Create dataset import job for Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(10)\n",
    "try:\n",
    "    users_create_dataset_import_job_response = personalize.create_dataset_import_job(\n",
    "        jobName = f\"import-sample-users-{date}\",\n",
    "        datasetArn = users_dataset_arn,\n",
    "        dataSource = {\n",
    "            \"dataLocation\": \"s3://{}/{}\".format(bucket, sample_user_filename)\n",
    "        },\n",
    "        roleArn = role_arn\n",
    "    )\n",
    "\n",
    "    users_dataset_import_job_arn = users_create_dataset_import_job_response['datasetImportJobArn']\n",
    "    print(json.dumps(users_dataset_import_job_arn, indent=2))\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-3-3. Create dataset import job for Items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(10)\n",
    "try:\n",
    "    items_create_dataset_import_job_response = personalize.create_dataset_import_job(\n",
    "        jobName = f\"import-sample-items-{date}\",\n",
    "        datasetArn = items_dataset_arn,\n",
    "        dataSource = {\n",
    "            \"dataLocation\": \"s3://{}/{}\".format(bucket, sample_item_filename)\n",
    "        },\n",
    "        roleArn = role_arn\n",
    "    )\n",
    "\n",
    "    items_dataset_import_job_arn = items_create_dataset_import_job_response['datasetImportJobArn']\n",
    "    print(json.dumps(items_dataset_import_job_arn, indent=2))\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Wait for Dataset Import Job to Have ACTIVE Status\n",
    "\n",
    "It can take a while before the import job completes, please wait until you see that it is active below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_time = time.time() + 3*60*60 # 3 hours\n",
    "while time.time() < max_time:\n",
    "    describe_dataset_import_job_response = personalize.describe_dataset_import_job(\n",
    "        datasetImportJobArn = items_dataset_import_job_arn\n",
    "    )\n",
    "    status = describe_dataset_import_job_response[\"datasetImportJob\"]['status']\n",
    "    print(\"DatasetImportJob: {}\".format(status))\n",
    "    \n",
    "    if status == \"ACTIVE\" or status == \"CREATE FAILED\":\n",
    "        break\n",
    "        \n",
    "    time.sleep(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Use custom resources\n",
    "\n",
    "In Amazon Personalize a trained model is called a Solution, each Solution can have many specific versions that relate to a given volume of data when the model was trained.\n",
    "\n",
    "To begin we will list all the recipies that are supported, a recipie is an algorithm that has not been trained on your data yet. After listing you'll select one and use that to build your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-1. Select Recipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_recipes_response = personalize.list_recipes()\n",
    "list_recipes = [list_recipes_response]\n",
    "while True:\n",
    "    if list_recipes_response.get('nextToken'):\n",
    "        list_recipes_response = personalize.list_recipes(nextToken=list_recipes_response['nextToken'])\n",
    "        list_recipes.append(list_recipes_response)\n",
    "    else:\n",
    "        break\n",
    "\n",
    "num = 1\n",
    "for response in list_recipes:\n",
    "    for i, recipes_name in enumerate(response['recipes']):\n",
    "        name = recipes_name['name']\n",
    "        recipeArn = recipes_name['recipeArn']\n",
    "\n",
    "        if recipes_name.get('domain'):\n",
    "            domain = recipes_name['domain']\n",
    "            print(f\"{num}.{name}, {recipeArn}, {domain}\")\n",
    "        else:\n",
    "            print(f\"{num}.{name}, {recipeArn}\")\n",
    "        num += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-2. Recipe - User Personalization\n",
    "The [User-Personalization](https://docs.aws.amazon.com/personalize/latest/dg/native-recipe-new-item-USER_PERSONALIZATION.html) (aws-user-personalization) recipe is optimized for all USER_PERSONALIZATION recommendation scenarios. When recommending items, it uses automatic item exploration.\n",
    "\n",
    "With automatic exploration, Amazon Personalize automatically tests different item recommendations, learns from how users interact with these recommended items, and boosts recommendations for items that drive better engagement and conversion. This improves item discovery and engagement when you have a fast-changing catalog, or when new items, such as news articles or promotions, are more relevant to users when fresh.\n",
    "\n",
    "You can balance how much to explore (where items with less interactions data or relevance are recommended more frequently) against how much to exploit (where recommendations are based on what we know or relevance). Amazon Personalize automatically adjusts future recommendations based on implicit user feedback.\n",
    "\n",
    "First, select the recipe by finding the ARN in the list of recipes above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe_arn = \"arn:aws:personalize:::recipe/aws-user-personalization\" # aws-user-personalization selected for demo purposes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-3. Create Solution\n",
    "\n",
    "First you will create the solution with the API, then you will create a version. It will take several minutes to train the model and thus create your version of a solution. Once it gets started and you are seeing the in progress notifications it is a good time to take a break, grab a coffee, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    create_solution_response = personalize.create_solution(\n",
    "        name = f\"personalize-sample-user-personalization-{date}\",\n",
    "        datasetGroupArn = dataset_group_arn,\n",
    "        recipeArn = recipe_arn\n",
    "    )\n",
    "\n",
    "    solution_arn = create_solution_response['solutionArn']\n",
    "    print(json.dumps(create_solution_response, indent=2))\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    solution_arn = create_solution_response['solutionArn']\n",
    "    print(f\"solution_arn : {solution_arn}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-4. Create Solution Version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Personalize 재학습에서는 trainingMode='UPDATE'로 변경해서 아래 작업을 다시 진행해 볼 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingMode = \"FULL\"\n",
    "# trainingMode = \"UPDATE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    create_solution_version_response = personalize.create_solution_version(\n",
    "        solutionArn = solution_arn,\n",
    "        trainingMode=trainingMode \n",
    "    )\n",
    "\n",
    "    solution_version_arn = create_solution_version_response['solutionVersionArn']\n",
    "    print(json.dumps(create_solution_version_response, indent=2))\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Wait for Solution Version to Have ACTIVE Status\n",
    "\n",
    "This will take approximately 40-50 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_time = time.time() + 3*60*60 # 3 hours\n",
    "while time.time() < max_time:\n",
    "    describe_solution_version_response = personalize.describe_solution_version(\n",
    "        solutionVersionArn = solution_version_arn\n",
    "    )\n",
    "    status = describe_solution_version_response[\"solutionVersion\"][\"status\"]\n",
    "    print(\"SolutionVersion: {}\".format(status))\n",
    "    \n",
    "    if status == \"ACTIVE\" or status == \"CREATE FAILED\":\n",
    "        break\n",
    "        \n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-5. Get Metrics of Solution Version\n",
    "\n",
    "Now that your solution and version exists, you can obtain the metrics for it to judge its performance. These metrics are not particularly good as it is a demo set of data, but with larger more complex datasets you should see improvements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    get_solution_metrics_response = personalize.get_solution_metrics(\n",
    "        solutionVersionArn = solution_version_arn\n",
    "    )\n",
    "    print(json.dumps(get_solution_metrics_response, indent=2))\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We recommend reading [the documentation](https://docs.aws.amazon.com/personalize/latest/dg/working-with-training-metrics.html) to understand the metrics, but we have also copied parts of the documentation below for convenience.\n",
    "\n",
    "You need to understand the following terms regarding evaluation in Personalize:\n",
    "\n",
    "- *Relevant recommendation* refers to a recommendation that matches a value in the testing data for the particular user.\n",
    "- *Rank* refers to the position of a recommended item in the list of recommendations. Position 1 (the top of the list) is presumed to be the most relevant to the user.\n",
    "- *Query* refers to the internal equivalent of a GetRecommendations call.\n",
    "\n",
    "The metrics produced by Personalize are:\n",
    "\n",
    "- coverage: The proportion of unique recommended items from all queries out of the total number of unique items in the training data (includes both the Items and Interactions datasets).\n",
    "- mean_reciprocal_rank_at_25: The [mean of the reciprocal ranks](https://en.wikipedia.org/wiki/Mean_reciprocal_rank) of the first relevant recommendation out of the top 25 recommendations over all queries. This metric is appropriate if you're interested in the single highest ranked recommendation.\n",
    "- normalized_discounted_cumulative_gain_at_K: Discounted gain assumes that recommendations lower on a list of recommendations are less relevant than higher recommendations. Therefore, each recommendation is discounted (given a lower weight) by a factor dependent on its position. To produce the [cumulative discounted gain](https://en.wikipedia.org/wiki/Discounted_cumulative_gain) (DCG) at K, each relevant discounted recommendation in the top K recommendations is summed together. The normalized discounted cumulative gain (NDCG) is the DCG divided by the ideal DCG such that NDCG is between 0 - 1. (The ideal DCG is where the top K recommendations are sorted by relevance.) Amazon Personalize uses a weighting factor of 1/log(1 + position), where the top of the list is position 1. This metric rewards relevant items that appear near the top of the list, because the top of a list usually draws more attention.\n",
    "- precision_at_K: The number of relevant recommendations out of the top K recommendations divided by K. This metric rewards precise recommendation of the relevant items."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Create and Wait for the Campaign\n",
    "\n",
    "Now that you have a working solution version you will need to create a campaign to use it with your applications. A campaign is a hosted solution version; an endpoint which you can query for recommendations. Pricing is set by estimating throughput capacity (requests from users for personalization per second). When deploying a campaign, you set a minimum transactions per second (TPS) value (`minProvisionedTPS`). This service, like many within AWS, will automatically scale based on demand, but if latency is critical, you may want to provision ahead for larger demand. For this demo, the minimum throughput threshold is set to 1. For more information, see the [pricing](https://aws.amazon.com/personalize/pricing/) page.\n",
    "\n",
    "As mentioned above, the user-personalization recipe used for our solution supports automatic exploration of \"cold\" items. You can control how much exploration is performed when creating your campaign. The `itemExplorationConfig` data type supports `explorationWeight` and `explorationItemAgeCutOff` parameters. Exploration weight determines how frequently recommendations include items with less interactions data or relevance. The closer the value is to 1.0, the more exploration. At zero, no exploration occurs and recommendations are based on current data (relevance). Exploration item age cut-off determines items to be explored based on time frame since latest interaction. Provide the maximum item age, in days since the latest interaction, to define the scope of item exploration. The larger the value, the more items are considered during exploration. For our campaign below, we'll specify an exploration weight of 0.5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6-1. Create Campaign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    if trainingMode == \"FULL\":\n",
    "        create_campaign_response = personalize.create_campaign(\n",
    "            name = f\"personalize-sample-camp-{date}\",\n",
    "            solutionVersionArn = solution_version_arn,\n",
    "            minProvisionedTPS = 1,\n",
    "            campaignConfig = {\n",
    "                \"itemExplorationConfig\": {\n",
    "                    \"explorationWeight\": \"0.3\",   ### Exploration 비율을 조정해 볼 수 있는 값\n",
    "                    \"explorationItemAgeCutOff\": \"20\"\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "    elif trainingMode == \"UPDATE\" and campaign_arn is not None:\n",
    "        create_campaign_response = personalize.update_campaign(\n",
    "            campaignArn = campaign_arn,\n",
    "            solutionVersionArn = solution_version_arn,\n",
    "            minProvisionedTPS = 1,\n",
    "            campaignConfig = {\n",
    "                \"itemExplorationConfig\": {\n",
    "                    \"explorationWeight\": \"0.3\",   ### Exploration 비율을 조정해 볼 수 있는 값\n",
    "                    \"explorationItemAgeCutOff\": \"20\"\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "\n",
    "    campaign_arn = create_campaign_response['campaignArn']\n",
    "    print(json.dumps(create_campaign_response, indent=2))\n",
    "except Exception as e:\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Wait for Campaign to Have ACTIVE Status\n",
    "\n",
    "This should take about 10 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_time = time.time() + 3*60*60 # 3 hours\n",
    "while time.time() < max_time:\n",
    "    describe_campaign_response = personalize.describe_campaign(\n",
    "        campaignArn = campaign_arn\n",
    "    )\n",
    "    status = describe_campaign_response[\"campaign\"][\"status\"]\n",
    "    print(\"Campaign: {}\".format(status))\n",
    "    \n",
    "    if status == \"ACTIVE\" or status == \"CREATE FAILED\":\n",
    "        break\n",
    "        \n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Get Sample Recommendations\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting a random user:\n",
    "user_id, item_id, _ ,_ ,_ ,_ = interaction_pd_data.sample().values[0]\n",
    "print(\"USER: {}\".format(user_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7-1. Call GetRecommendations\n",
    "\n",
    "Using the user that you obtained above, the lines below will get recommendations for you and return the list of items that are recommended.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_recommendations_response = personalize_runtime.get_recommendations(\n",
    "    campaignArn = campaign_arn,\n",
    "    userId = str(user_id),\n",
    ")\n",
    "# Update DF rendering\n",
    "pd.set_option('display.max_rows', 30)\n",
    "\n",
    "print(\"Recommendations for user: \", user_id)\n",
    "\n",
    "item_list_first = get_recommendations_response['itemList']\n",
    "\n",
    "recommendation_list = []\n",
    "\n",
    "for item in item_list_first:\n",
    "    title = item['itemId']\n",
    "    score = item['score']\n",
    "\n",
    "    recommendation_list.append([title, score])\n",
    "    \n",
    "recommendations_df = pd.DataFrame(recommendation_list, columns = ['OriginalRecs-items','OriginalRecs-score'])\n",
    "recommendations_df[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7-2. Create new filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sts_client = boto3.client(\"sts\")\n",
    "account_id = sts_client.get_caller_identity()[\"Account\"]\n",
    "region_name = boto3.Session().region_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_name = f'sample-filter-not-in-check-and-purchased-{date}'\n",
    "filter_arn = f\"arn:aws:personalize:{region_name}:{account_id}:filter/{filter_name}\"\n",
    "try:\n",
    "    personalize.delete_filter(\n",
    "        filterArn=filter_arn\n",
    "    )\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    res_filter = personalize.create_filter(\n",
    "        name=filter_name,\n",
    "        datasetGroupArn=dataset_group_arn,\n",
    "        filterExpression='EXCLUDE ItemID WHERE Interactions.event_type IN (\"checked\", \"purchased\")'\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Wait for creating a filter to Have ACTIVE Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_time = time.time() + 3*60*60 # 3 hours\n",
    "while time.time() < max_time:\n",
    "    describe_filter_response = personalize.describe_filter(\n",
    "        filterArn = filter_arn\n",
    "    )\n",
    "    status = describe_filter_response[\"filter\"][\"status\"]\n",
    "    print(\"Filter: {}\".format(status))\n",
    "    \n",
    "    if status == \"ACTIVE\" or status == \"CREATE FAILED\":\n",
    "        break\n",
    "        \n",
    "    time.sleep(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7-3. Call GetRecommendations with Filter (exclude 'checked' and 'purchased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_recommendations_response = personalize_runtime.get_recommendations(\n",
    "    campaignArn = campaign_arn,\n",
    "    userId = str(user_id),\n",
    "    filterArn=res_filter['filterArn']\n",
    ")\n",
    "# Update DF rendering\n",
    "pd.set_option('display.max_rows', 30)\n",
    "\n",
    "print(\"Recommendations for user: \", user_id)\n",
    "\n",
    "item_list = get_recommendations_response['itemList']\n",
    "\n",
    "recommendation_list = []\n",
    "\n",
    "for item in item_list:\n",
    "    title = item['itemId']\n",
    "    score = item['score']\n",
    "    recommendation_list.append([title, score])\n",
    "    \n",
    "\n",
    "new_rec_DF = pd.DataFrame(recommendation_list, columns = ['Filtered-items','Filtered-score'])\n",
    "try:\n",
    "    recommendations_df.drop(['Filtered-items','Filtered-score'], axis=1, inplace=True)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "recommendations_df = recommendations_df.join(new_rec_DF)\n",
    "recommendations_df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_items_list = []\n",
    "for inter_data in interaction_data:\n",
    "    if inter_data[0] == user_id:\n",
    "        filter_items_list.append(inter_data[1])\n",
    "print(f\"filter_items_list : {filter_items_list}\")\n",
    "for rec_list in recommendations_df['Filtered-items']:\n",
    "    if rec_list in filter_items_list:\n",
    "        print(f\"rec_list : {rec_list}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7-4. Creating an Event Tracker\n",
    "\n",
    "Before your recommendation system can respond to real time events you will need an event tracker, the code below will generate one and can be used going forward with this lab. Feel free to name it something more clever."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import boto3\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and Config\n",
    "# Recommendations from Event data\n",
    "personalize = boto3.client('personalize')\n",
    "personalize_runtime = boto3.client('personalize-runtime')\n",
    "\n",
    "# Establish a connection to Personalize's Event Streaming\n",
    "personalize_events = boto3.client(service_name='personalize-events')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    response = personalize.create_event_tracker(\n",
    "        name=f'SampleTracker-{date}',\n",
    "        datasetGroupArn=dataset_group_arn\n",
    "    )\n",
    "    event_tracker_arn = response['eventTrackerArn']\n",
    "    TRACKING_ID = response['trackingId']\n",
    "    print(f\"event_tracker_arn : {event_tracker_arn} ,\\nTRACKING_ID : {TRACKING_ID}\")\n",
    "except Exception as e:\n",
    "    response = personalize.describe_event_tracker(\n",
    "        eventTrackerArn=event_tracker_arn\n",
    "    )\n",
    "    event_tracker_arn=response['eventTracker']['eventTrackerArn']\n",
    "    TRACKING_ID = response['eventTracker']['trackingId']\n",
    "    print(f\"event_tracker_arn : {event_tracker_arn} ,\\nTRACKING_ID : {TRACKING_ID}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7-4-1. Put-Events with Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_ID = str(user_id)\n",
    "ITEM_ID = recommendations_df['Filtered-items'][0]\n",
    "print(f\"USER_ID : {USER_ID}, ITEM_ID : {ITEM_ID}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_dict = {}\n",
    "\n",
    "# Configure Session\n",
    "try:\n",
    "    session_ID = session_dict[USER_ID]\n",
    "except:\n",
    "    session_dict[USER_ID] = str(uuid.uuid1())\n",
    "    session_ID = session_dict[USER_ID]\n",
    "    \n",
    "print(f\"session_ID : {session_ID}\")\n",
    "print(f\"USER_ID : {USER_ID}\")\n",
    "print(f\"ITEM_ID : {ITEM_ID}\")\n",
    "\n",
    "# Configure Properties:\n",
    "event = {\n",
    "    \"itemId\": ITEM_ID,\n",
    "    \"itemtype\": \"AAA\"\n",
    "}\n",
    "event_json = json.dumps(event)\n",
    "\n",
    "# Make Call\n",
    "personalize_events.put_events(\n",
    "trackingId = TRACKING_ID,\n",
    "userId= USER_ID,\n",
    "sessionId = session_ID,\n",
    "eventList = [{\n",
    "    'sentAt': int(time.time()),\n",
    "    'recommendationId' : get_recommendations_response['recommendationId'],\n",
    "    'eventType': 'checked',\n",
    "    'properties': event_json\n",
    "    }]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_recommendations_response = personalize_runtime.get_recommendations(\n",
    "    campaignArn = campaign_arn,\n",
    "    userId = str(user_id),\n",
    "    filterArn=res_filter['filterArn'] ### Filters\n",
    ")\n",
    "# Update DF rendering\n",
    "pd.set_option('display.max_rows', 30)\n",
    "\n",
    "print(\"Recommendations for user: \", user_id)\n",
    "\n",
    "item_list = get_recommendations_response['itemList']\n",
    "\n",
    "recommendation_list = []\n",
    "\n",
    "for item in item_list:\n",
    "    title = item['itemId']\n",
    "    score = item['score']\n",
    "    recommendation_list.append([title, score])\n",
    "    \n",
    "\n",
    "new_rec_DF = pd.DataFrame(recommendation_list, columns = ['Put-event-items','Put-event'])\n",
    "try:\n",
    "    recommendations_df.drop(['Put-event-items','Put-event'], axis=1, inplace=True)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "recommendations_df = recommendations_df.join(new_rec_DF)\n",
    "recommendations_df[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7-5. Call GetRecommendations with Filter and Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_recommendations_response = personalize_runtime.get_recommendations(\n",
    "    campaignArn = campaign_arn,\n",
    "    userId = str(user_id),\n",
    "    filterArn=res_filter['filterArn'],\n",
    "    context={\n",
    "          'ITEM_TYPE': 'AAA'\n",
    "      },\n",
    ")\n",
    "# Update DF rendering\n",
    "pd.set_option('display.max_rows', 30)\n",
    "\n",
    "print(\"Recommendations for user: \", user_id)\n",
    "\n",
    "item_list = get_recommendations_response['itemList']\n",
    "\n",
    "recommendation_list = []\n",
    "\n",
    "for item in item_list:\n",
    "    title = item['itemId']\n",
    "    score = item['score']\n",
    "    recommendation_list.append([title, score])\n",
    "    \n",
    "\n",
    "new_rec_DF = pd.DataFrame(recommendation_list, columns = ['Context-items','Context-score'])\n",
    "\n",
    "try:\n",
    "    recommendations_df.drop(['Context-items','Context-score'], axis=1, inplace=True)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "recommendations_df = recommendations_df.join(new_rec_DF)\n",
    "recommendations_df[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7-6. Call GetRecommendations with Impression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_ID = str(user_id)\n",
    "ITEM_ID = recommendations_df['Context-items'][0]\n",
    "print(f\"USER_ID : {USER_ID}, ITEM_ID : {ITEM_ID}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Session\n",
    "try:\n",
    "    session_ID = session_dict[USER_ID]\n",
    "except:\n",
    "    session_dict[USER_ID] = str(uuid.uuid1())\n",
    "    session_ID = session_dict[USER_ID]\n",
    "    \n",
    "    \n",
    "impression_list = [item[0] for item in recommendation_list[:5]]\n",
    "\n",
    "print(f\"session_ID : {session_ID}\")\n",
    "print(f\"ITEM_ID : {ITEM_ID}\")\n",
    "print(f\"impression_list : {impression_list}\")\n",
    "\n",
    "# Configure Properties:\n",
    "event = {\n",
    "    \"itemId\": ITEM_ID,\n",
    "    \"itemtype\": \"BBB\"\n",
    "}\n",
    "event_json = json.dumps(event)\n",
    "\n",
    "# Make Call\n",
    "personalize_events.put_events(\n",
    "trackingId = TRACKING_ID,\n",
    "userId= USER_ID,\n",
    "sessionId = session_ID,\n",
    "eventList = [{\n",
    "    'sentAt': int(time.time()),\n",
    "    'impression': impression_list, ## Explicit impressions\n",
    "    'eventType': 'purchased',\n",
    "    'properties': event_json\n",
    "    }]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_recommendations_response = personalize_runtime.get_recommendations(\n",
    "    campaignArn = campaign_arn,\n",
    "    userId = str(user_id),\n",
    "    filterArn=res_filter['filterArn'],\n",
    "    context={\n",
    "          'ITEM_TYPE': 'AAA'\n",
    "      },\n",
    ")\n",
    "# Update DF rendering\n",
    "pd.set_option('display.max_rows', 30)\n",
    "\n",
    "print(\"Recommendations for user: \", user_id)\n",
    "\n",
    "item_list = get_recommendations_response['itemList']\n",
    "\n",
    "recommendation_list = []\n",
    "\n",
    "for item in item_list:\n",
    "    title = item['itemId']\n",
    "    score = item['score']\n",
    "    recommendation_list.append([title, score])\n",
    "    \n",
    "\n",
    "new_rec_DF = pd.DataFrame(recommendation_list, columns = ['Impression-items','Impression-score'])\n",
    "\n",
    "try:\n",
    "    recommendations_df.drop(['Impression-items','Impression-score'], axis=1, inplace=True)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "print(f\"impression_list : {impression_list}\")\n",
    "recommendations_df = recommendations_df.join(new_rec_DF)\n",
    "recommendations_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7-7. Call GetRecommendations after doing put_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIMESTAMP_10 = time.mktime((datetime.now()-timedelta(days=10)).timetuple())\n",
    "TIMESTAMP_10 = int(TIMESTAMP_10)\n",
    "\n",
    "TIMESTAMP_30 = time.mktime((datetime.now()-timedelta(days=30)).timetuple())\n",
    "TIMESTAMP_30 = int(TIMESTAMP_30)\n",
    "print(f\"TIMESTAMP_10 : {TIMESTAMP_10}, TIMESTAMP_30 : {TIMESTAMP_30}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ITEM_ID_10 = item_data[-1][0] +30000\n",
    "new_ITEM_ID_30 = item_data[-1][0] +20000\n",
    "print(f\"new_ITEM_ID_10 : {new_ITEM_ID_10} , new_ITEM_ID_30 : {new_ITEM_ID_30}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    new_ITEM_ID_30 = item_data[-1][0] + 20000 + i\n",
    "    # Configure Properties:\n",
    "    item_meta = {\n",
    "        'ITEM_META1': 'A_ITEM_1',\n",
    "        'ITEM_META2':'B_ITEM_1',\n",
    "        'CREATION_TIMESTAMP':TIMESTAMP_30\n",
    "    }\n",
    "    item_meta_json = json.dumps(item_meta)\n",
    "\n",
    "    personalize_events.put_items(\n",
    "        datasetArn=items_dataset_arn,\n",
    "        items=[\n",
    "            {\n",
    "                'itemId': str(new_ITEM_ID_30),\n",
    "                'properties': item_meta_json\n",
    "            },\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    new_ITEM_ID_10 = item_data[-1][0] + 30000 + i\n",
    "    # Configure Properties:\n",
    "    item_meta = {\n",
    "        'ITEM_META1': 'A_ITEM_1',\n",
    "        'ITEM_META2':'B_ITEM_1',\n",
    "        'CREATION_TIMESTAMP':TIMESTAMP_10\n",
    "    }\n",
    "    item_meta_json = json.dumps(item_meta)\n",
    "\n",
    "    personalize_events.put_items(\n",
    "        datasetArn=items_dataset_arn,\n",
    "        items=[\n",
    "            {\n",
    "                'itemId': str(new_ITEM_ID_10),\n",
    "                'properties': item_meta_json\n",
    "            },\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_recommendations_response = personalize_runtime.get_recommendations(\n",
    "    campaignArn = campaign_arn,\n",
    "    userId = str(USER_ID),\n",
    ")\n",
    "# Update DF rendering\n",
    "pd.set_option('display.max_rows', 30)\n",
    "\n",
    "print(\"Recommendations for user: \", USER_ID)\n",
    "\n",
    "item_list_first = get_recommendations_response['itemList']\n",
    "\n",
    "recommendation_list_new_item = []\n",
    "\n",
    "for item in item_list_first:\n",
    "    title = item['itemId']\n",
    "    score = item['score']\n",
    "    recommendation_list_new_item.append([title, score])\n",
    "    \n",
    "new_rec_DF = pd.DataFrame(recommendation_list_new_item, columns = ['new-put-items','new-put-items-score'])\n",
    "\n",
    "try:\n",
    "    recommendations_df.drop(['new-put-items','new-put-items-score'], axis=1, inplace=True)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "recommendations_df = recommendations_df.join(new_rec_DF)\n",
    "recommendations_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7-8. Call GetRecommendations after doing put_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_USER_ID = user_data[-1][0] + 100\n",
    "\n",
    "print(f\"USER_ID : {new_USER_ID}\")\n",
    "\n",
    "# Configure Properties:\n",
    "user_meta = {\n",
    "    'USER_META1': str(user_data[int(USER_ID)-1][1]),\n",
    "    'USER_META2': user_data[int(USER_ID)-1][2],\n",
    "    'CREATION_TIMESTAMP':int(time.time())\n",
    "}\n",
    "user_meta_json = json.dumps(user_meta)\n",
    "\n",
    "personalize_events.put_users(\n",
    "    datasetArn=users_dataset_arn,\n",
    "    users=[\n",
    "        {\n",
    "            'userId': str(new_USER_ID),\n",
    "            'properties': user_meta_json\n",
    "        },\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_recommendations_response = personalize_runtime.get_recommendations(\n",
    "    campaignArn = campaign_arn,\n",
    "    userId = str(new_USER_ID),\n",
    ")\n",
    "# Update DF rendering\n",
    "pd.set_option('display.max_rows', 30)\n",
    "\n",
    "print(\"Recommendations for user: \", new_USER_ID)\n",
    "\n",
    "item_list_first = get_recommendations_response['itemList']\n",
    "\n",
    "recommendation_list_new_user = []\n",
    "\n",
    "for item in item_list_first:\n",
    "    title = item['itemId']\n",
    "    score = item['score']\n",
    "    recommendation_list_new_user.append([title, score])\n",
    "    \n",
    "new_rec_DF = pd.DataFrame(recommendation_list_new_user, columns = ['new-put-users','new-put-users-score'])\n",
    "\n",
    "try:\n",
    "    recommendations_df.drop(['new-put-users','new-put-users-score'], axis=1, inplace=True)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "recommendations_df = recommendations_df.join(new_rec_DF)\n",
    "recommendations_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for val in list(recommendations_df['OriginalRecs-items']):\n",
    "    if val in list(recommendations_df['new-put-users']):\n",
    "        print(val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review\n",
    "\n",
    "Using the codes above you have successfully trained a deep learning model to generate recommendations based on prior user behavior. Think about other types of problems where this data is available and what it might look like to build a system like this to offer those recommendations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Amazon Personalize Immersion Day](https://catalog.us-east-1.prod.workshops.aws/workshops/c5a0c80f-1a42-442c-b2c0-956b38d4dc48/en-US) \n",
    "- [amazon-personalize-samples](https://github.com/aws-samples/amazon-personalize-samples)\n",
    "- [Amazon Personalize 기반으로 실시간 추천 사이트 만들기](https://catalog.us-east-1.prod.workshops.aws/workshops/ed82a5d4-6630-41f0-a6a1-9345898fa6ec/ko-KR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
